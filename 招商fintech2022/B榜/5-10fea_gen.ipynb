{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error, log_loss\n",
    "pd.options.display.precision = 15\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = './output/'\n",
    "train_path = './data/original_train.csv'\n",
    "test_path = './data/original_test_B.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 51) (12000, 50)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 41) (12000, 40)\n"
     ]
    }
   ],
   "source": [
    "# 删除掉testb中与train分布不一致的特征列\n",
    "need_drop_col = ['CUR_YEAR_MON_AGV_TRX_CNT','CUR_YEAR_COR_DMND_DPS_DAY_AVG_BAL','CUR_YEAR_COR_DPS_YEAR_DAY_AVG_INCR','CUR_YEAR_MID_BUS_INC','AI_STAR_SCO',\n",
    "'CUR_MON_COR_DPS_MON_DAY_AVG_BAL','ICO_CUR_MON_ACM_TRX_AMT','MON_12_AGV_TRX_CNT','MON_12_ACM_LVE_ACT_CNT','MON_12_AGV_LVE_ACT_CNT']\n",
    "\n",
    "my_guess = [#\n",
    "# 'MON_12_AGV_TRX_CNT',#1\n",
    "# 'MON_12_ACM_ENTR_ACT_CNT',#0.98\n",
    "# 'MON_12_AGV_ENTR_ACT_CNT',#0.98\n",
    "# 'MON_12_ACM_LVE_ACT_CNT',#1\n",
    "# 'MON_12_AGV_LVE_ACT_CNT'#1\n",
    "\n",
    "#'LAST_12_MON_COR_DPS_TM_PNT_BAL_PEAK_VAL'\n",
    "# 'PUB_TO_PRV_TRX_AMT_CUR_YEAR',#线下微掉\n",
    "#'LAST_12_MON_COR_DPS_DAY_AVG_BAL', #据说线上掉的厉害，直接70，线下也是掉的厉害\n",
    "#'NB_RCT_3_MON_LGN_TMS_AGV' #未验证，线下微涨\n",
    "#'REG_DT', #注册日期\n",
    "# 'REG_CPT',# 注册资本 这个个人觉得应该影响不大\n",
    "#'OPN_TM' #开户日期\n",
    "\n",
    "]\n",
    "\n",
    "train = train.drop(need_drop_col + my_guess, axis=1)\n",
    "test = test.drop(need_drop_col + my_guess, axis=1)\n",
    "# train = train[['CUST_UID','LABEL'] + remain_col]\n",
    "# test = test[['CUST_UID'] + remain_col]\n",
    "\n",
    "print(train.shape,test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分布修正\n",
    "train['AGN_CUR_YEAR_AMT'] = train['AGN_CUR_YEAR_AMT'].apply(lambda x: np.log(x)-1.15)\n",
    "train['AGN_CUR_YEAR_WAG_AMT'] = train['AGN_CUR_YEAR_WAG_AMT'].apply(lambda x: np.log(x)-1.15)\n",
    "\n",
    "test['AGN_CUR_YEAR_AMT'] = test['AGN_CUR_YEAR_AMT'].apply(lambda x: np.log(x))\n",
    "test['AGN_CUR_YEAR_WAG_AMT'] = test['AGN_CUR_YEAR_WAG_AMT'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 10/39 [00:00<00:00, 78.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 88.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 组合二阶特征\n",
    "test['LABEL']=-1\n",
    "data = pd.concat([train,test]).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "original_fea = list(train.columns)[2:]\n",
    "corr_fea = data[list(data.columns)].corr()\n",
    "#list(corr_fea['AGN_CUR_YEAR_WAG_AMT'][corr_fea['AGN_CUR_YEAR_WAG_AMT'] > 0.3].index)\n",
    "from tqdm import tqdm\n",
    "cat_cols = ['MON_12_CUST_CNT_PTY_ID','AI_STAR_SCO','WTHR_OPN_ONL_ICO',\n",
    "'SHH_BCK','LGP_HLD_CARD_LVL','NB_CTC_HLD_IDV_AIO_CARD_SITU'] #'COR_KEY_PROD_HLD_NBR',\n",
    "history_data = []\n",
    "very_low_corr_fea = []\n",
    "print(len(list(corr_fea.columns)[2:]))\n",
    "for col1 in tqdm(list(train.columns)[2:]):\n",
    "    if col1 in cat_cols: continue\n",
    "    # if len(list(corr_fea[col1][corr_fea[col1] > 0.3].index)) <2:\n",
    "    #     very_low_corr_fea.append(col1)\n",
    "    #print(len(list(corr_fea[col1][corr_fea[col1] > 0.3].index)))\n",
    "    for col2 in list(corr_fea[col1][abs(corr_fea[col1] )> 0.3].index):\n",
    "        if col1 == col2 or sorted([col1,col2]) in history_data: continue\n",
    "        history_data.append(sorted([col1,col2]))\n",
    "        train[f'corr_{col1}_{col2}_diff'] = train[col1] - train[col2]\n",
    "        train[f'corr_{col1}_{col2}_rate'] = train[col1]/train[col2]\n",
    "        train[f'corr_{col1}_{col2}_add'] = train[col1] + train[col2]\n",
    "        train[f'corr_{col1}_rate'] = train[col1] /train[f'corr_{col1}_{col2}_add'] \n",
    "        train[f'corr_{col2}_rate'] = train[col2] /train[f'corr_{col1}_{col2}_add'] \n",
    "\n",
    "        test[f'corr_{col1}_{col2}_diff'] = test[col1] - test[col2]\n",
    "        test[f'corr_{col1}_{col2}_rate'] = test[col1]/test[col2]\n",
    "        test[f'corr_{col1}_{col2}_add'] = test[col1] + test[col2]\n",
    "        test[f'corr_{col1}_rate'] = test[col1] /test[f'corr_{col1}_{col2}_add'] \n",
    "        test[f'corr_{col2}_rate'] = test[col2] /test[f'corr_{col1}_{col2}_add']\n",
    "print(len(history_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手工特征\n",
    "def check_duplic_cols(feature,his_features,sorte_flag = True):\n",
    "    if sorte_flag:\n",
    "        if sorted(feature) in his_features:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if feature in his_features:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "def gen_diff_fea(df, features,his_features = []):\n",
    "    try:\n",
    "        for fea in features:\n",
    "            if check_duplic_cols(fea,his_features): continue\n",
    "            df[f'hand_{fea[0]}_{fea[1]}_diff'] = train[fea[0]] - train[fea[1]]\n",
    "            his_features.append(sorted(fea))\n",
    "        return df\n",
    "    except:\n",
    "        return df\n",
    "def gen_rate_fea(df,features,his_features = []):\n",
    "    try:\n",
    "        for fea in features:\n",
    "            if check_duplic_cols(fea,his_features,sorte_flag =False): continue\n",
    "            df[f'hand_{fea[0]}_{fea[1]}_rate'] = train[fea[0]]/train[fea[1]]\n",
    "            his_features.append(fea)\n",
    "        return df\n",
    "    except:\n",
    "        return df\n",
    "\n",
    "rate_features = [['MON_12_ACT_IN_50_UP_CNT_PTY_QTY','MON_12_ACT_OUT_50_UP_CNT_PTY_QTY'],['MON_12_EXT_SAM_TRSF_IN_AMT','MON_12_EXT_SAM_TRSF_OUT_AMT'],\n",
    "['CUR_MON_EXT_SAM_CUST_TRSF_IN_AMT','CUR_MON_EXT_SAM_CUST_TRSF_OUT_AMT'],['MON_6_50_UP_ENTR_ACT_CNT','MON_6_50_UP_LVE_ACT_CNT'],['MON_12_EXT_SAM_AMT','MON_12_EXT_SAM_NM_TRSF_OUT_CNT']]\n",
    "train = gen_rate_fea(train, rate_features ,his_features = [])\n",
    "test = gen_rate_fea(test, rate_features ,his_features = [])\n",
    "\n",
    "diff_features = [['MON_12_EXT_SAM_AMT','MON_12_EXT_SAM_NM_TRSF_OUT_CNT']]\n",
    "train = gen_diff_fea(train, diff_features ,his_features = [])\n",
    "test = gen_diff_fea(test, diff_features ,his_features = [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 259) (12000, 259)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:00<00:00, 4450.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(40000, 255) (12000, 255)\n"
     ]
    }
   ],
   "source": [
    "# 删除重复特征\n",
    "print(train.shape,test.shape)\n",
    "corr_fea = train[list(train.columns)].corr()\n",
    "#list(corr_fea['AGN_CUR_YEAR_WAG_AMT'][corr_fea['AGN_CUR_YEAR_WAG_AMT'] > 0.3].index)\n",
    "from tqdm import tqdm\n",
    "cat_cols = ['MON_12_CUST_CNT_PTY_ID','AI_STAR_SCO','WTHR_OPN_ONL_ICO',\n",
    "'SHH_BCK','LGP_HLD_CARD_LVL','NB_CTC_HLD_IDV_AIO_CARD_SITU'] #'COR_KEY_PROD_HLD_NBR',\n",
    "\n",
    "drop_data = ['CUR_YEAR_MON_AGV_']\n",
    "very_low_corr_fea = []\n",
    "print(len(list(corr_fea.columns)[2:]))\n",
    "#print(corr_fea)\n",
    "for col1 in tqdm(list(train.columns)[2:]):\n",
    "    if col1 in cat_cols: continue\n",
    "    # if len(list(corr_fea[col1][corr_fea[col1] > 0.3].index)) <2:\n",
    "    #     very_low_corr_fea.append(col1)\n",
    "    #print(len(list(corr_fea[col1][corr_fea[col1] > 0.3].index)))\n",
    "    for col2 in list(corr_fea[col1][corr_fea[col1] == 1].index):\n",
    "        if col1 == col2 or sorted([col1,col2]) in drop_data: continue\n",
    "        drop_data.append(sorted([col1,col2]))\n",
    "for col in drop_data:\n",
    "    if (col[0] in list(train.columns)) and (col[1] in list(train.columns)):\n",
    "        train = train.drop([col[0]], axis=1)\n",
    "        test = test.drop([col[0]], axis=1)\n",
    "       \n",
    "\n",
    "print(len(drop_data))\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train_fea_genb4.csv',index=None)\n",
    "test.to_csv('./data/test_B_fea_genb4.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2e8f04d65c62c49dbc0f2adda76bbd103f82c3255fc54c7e3855bd92e2af645"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
