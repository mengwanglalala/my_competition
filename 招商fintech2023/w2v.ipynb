{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "train_view = pd.read_csv('/data/train_view.csv',encoding='gbk' )\n",
    "testa_view = pd.read_csv('/data/testa_view.csv',encoding='gbk' )\n",
    "\n",
    "train_view = pd.concat([train_view,testa_view],axis=0)\n",
    "\n",
    "train_view = train_view.sort_values(['cust_wid','acs_tm'])\n",
    "train_view['date'] = train_view['acs_tm'].str.split().str.get(0)\n",
    "\n",
    "train_view['acs_tm'] = train_view['date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d') if type(x)==str else pd.NaT)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "df = train_view\n",
    "df['page_id'] = df['page_id'].astype(str)\n",
    "# 计算每个用户操作的日期列表，并按照日期顺序排序\n",
    "date_series = df['acs_tm'].apply(lambda x: x.date())\n",
    "operate_dates = df.groupby('cust_wid')['acs_tm'].apply(lambda x: sorted(set(x.apply(lambda y: y.date()))))\n",
    "\n",
    "# 计算每个用户操作的page_id序列\n",
    "operate_pages = df.groupby('cust_wid')['page_id'].apply(list)\n",
    "\n",
    "# 计算每个用户登陆天数\n",
    "num_login_days = operate_dates.apply(len)\n",
    "\n",
    "# 计算每个用户最长连续操作天数\n",
    "max_consecutive_days = {}\n",
    "for cust_wid, dates in operate_dates.iteritems():\n",
    "    max_consecutive_days[cust_wid] = 1\n",
    "    consecutive_days = 1\n",
    "    for i in range(1, len(dates)):\n",
    "        if (dates[i] - dates[i-1]).days == 1:\n",
    "            consecutive_days += 1\n",
    "            max_consecutive_days[cust_wid] = max(max_consecutive_days[cust_wid], consecutive_days)\n",
    "        else:\n",
    "            consecutive_days = 1\n",
    "\n",
    "# 输出结果\n",
    "result = pd.DataFrame({'num_login_days': num_login_days,\n",
    "                       'max_consecutive_days': pd.Series(max_consecutive_days),\n",
    "                       'operate_pages': operate_pages})\n",
    "print(result)\n",
    "result = result.reset_index().rename(columns={'index': 'cust_wid'})\n",
    "result.head()\n",
    "from gensim.models import Word2Vec\n",
    "df = result\n",
    "# 将page_id序列转化为一个句子，每个page_id作为一个单词\n",
    "sentences = [list(df['operate_pages'].apply(lambda x: ' '.join([str(x_data) for x_data in x])))]\n",
    "len(sentences[0])#\n",
    "\n",
    "# 训练word2vec模型\n",
    "model = Word2Vec(sentences=sentences[0], vector_size=20, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 获取所有用户的embedding表示\n",
    "from tqdm import tqdm\n",
    "user_embeddings = {}\n",
    "index = 0\n",
    "for cust_wid in tqdm(list(result['cust_wid'])):\n",
    "    #print(cust_wid)\n",
    "    user_sentences = sentences[0][index]\n",
    "    #print(user_sentences)\n",
    "    user_embedding = np.zeros((20,))\n",
    "    for word in user_sentences:\n",
    "        if word in model.wv.index_to_key:\n",
    "            user_embedding += model.wv[word]\n",
    "            \n",
    "    user_embedding /= len(user_sentences)\n",
    "    user_embeddings[cust_wid] = user_embedding\n",
    "    index += 1\n",
    "\n",
    "# 将结果保存为DataFrame格式\n",
    "embedding_df = pd.DataFrame.from_dict(user_embeddings, orient='index', columns=[f'w2v_view_embedding_{i+1}' for i in range(20)])\n",
    "embedding_df.index.name = 'cust_wid'\n",
    "\n",
    "embedding_df.reset_index().to_csv('all_view_w2v_emb.csv',index = 0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
