{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../temp_data/train_all_le.pickle')\n",
    "for col in ['videoid', 'tag', 'is_like', 'is_favourite', 'is_share', 'is_finish']:\n",
    "    del df_train[col]\n",
    "gc.collect()\n",
    "df_train['seq_no_rank'] = df_train.groupby('userid').cumcount(ascending=False)\n",
    "df_train['seq_no_rank'] = df_train['seq_no_rank'].astype(np.int16)\n",
    "tmp = pd.read_pickle('../temp_data/train_all_le.pickle')\n",
    "del tmp['userid']\n",
    "\n",
    "df_train = pd.concat([df_train, tmp], axis=1)\n",
    "\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "df_train = df_train[df_train['seq_no_rank'] < 1600].reset_index(drop=True)\n",
    "df_valid = df_train[df_train['seq_no_rank'] < 100].reset_index(drop=True)\n",
    "df_train = df_train[df_train['seq_no_rank'] >= 100].reset_index(drop=True)\n",
    "print(df_valid.shape[0], df_valid['userid'].nunique())\n",
    "df_valid.to_pickle('../temp_data/valid.pickle')\n",
    "df_train.to_pickle('../temp_data/train.pickle')\n",
    "del df_train\n",
    "del df_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype_list = ['train','valid','test']\n",
    "drop_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    for col in tqdm(df.columns):\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(\n",
    "                        np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datatype in datatype_list:\n",
    "    if datatype == 'test':\n",
    "        filename = f'../temp_data/test_all_le.pickle'\n",
    "    else:\n",
    "        filename = f'../temp_data/{datatype}.pickle'\n",
    "    df_data = pd.read_pickle(filename)\n",
    "    if datatype == 'train':\n",
    "        #df_data = df_data.sample(n=n_samples, random_state=seed).reset_index(drop=True)\n",
    "        pass\n",
    "    elif datatype == 'valid':\n",
    "        #df_data = df_data.iloc[:478206]\n",
    "        pass\n",
    "    if datatype in ['train', 'valid']:\n",
    "        del df_data['seq_no_rank']   \n",
    "    display(df_data)\n",
    "    \n",
    "#     df = pd.read_pickle(f'/home/workspace/output/feats/user_tag_cnt.pickle')\n",
    "#     df_data = pd.merge(left=df_data, right=df, how='left',on = ['userid','tag'])\n",
    "#     df_data.head()   \n",
    "    \n",
    "#     for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "#         df = pd.read_pickle(f'/home/workspace/output/feats/user_tag_{col}_sum.pickle')\n",
    "#         df_data = pd.merge(left=df_data, right=df, how='left',on = ['userid','tag'])\n",
    "#     df_data.head()\n",
    "    \n",
    "    # 统计各用户，id，tag的总数量\n",
    "    for col in tqdm(['userid', 'videoid', 'tag']):\n",
    "        df = pd.read_pickle(f'../temp_data/{col}_cnt.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = [col])\n",
    "        \n",
    "    \n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        df = pd.read_pickle(f'../temp_data/tag_{col}_mean.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['tag'])\n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        if f'videoid_{col}_mean' in drop_list: continue\n",
    "        df = pd.read_pickle(f'../temp_data/videoid_{col}_mean.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['videoid'])\n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        if f'userid_{col}_mean' in drop_list: continue\n",
    "        df = pd.read_pickle(f'../temp_data/userid_{col}_mean.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['userid'])\n",
    "\n",
    "\n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        if f'tag_{col}_sum' in drop_list: continue\n",
    "        df = pd.read_pickle(f'../temp_data/tag_{col}_sum.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['tag'])\n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        if f'videoid_{col}_sum' in drop_list: continue\n",
    "        df = pd.read_pickle(f'../temp_data/videoid_{col}_sum.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['videoid'])\n",
    "    for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "        if f'userid_{col}_sum' in drop_list: continue\n",
    "        df = pd.read_pickle(f'../temp_data/userid_{col}_sum.pickle')\n",
    "        df_data = pd.merge(left=df_data, right=df, how='left',on = ['userid'])\n",
    "    df_data.head()\n",
    "\n",
    "\n",
    "    # for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "    #     if f'videoid_{col}_sum' in drop_list: continue\n",
    "    #     df = pd.read_pickle(f'/home/workspace/output/feats/videoid_{col}_std.pickle')\n",
    "    #     df_data = pd.merge(left=df_data, right=df, how='left',on = ['videoid'])\n",
    "    # for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "    #     if f'tag_{col}_sum' in drop_list: continue\n",
    "    #     df = pd.read_pickle(f'/home/workspace/output/feats/tag_{col}_std.pickle')\n",
    "    #     df_data = pd.merge(left=df_data, right=df, how='left',on = ['tag'])\n",
    "    # for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "    #     if f'userid_{col}_sum' in drop_list: continue\n",
    "    #     df = pd.read_pickle(f'/home/workspace/output/feats/userid_{col}_std.pickle')\n",
    "    #     df_data = pd.merge(left=df_data, right=df, how='left',on = ['userid'])\n",
    "\n",
    "    # df_data = reduce_mem_usage(df_data)\n",
    "    # df_data.head() \n",
    "\n",
    "    # for col in tqdm(['is_like', 'is_favourite', 'is_share', 'is_finish']):\n",
    "    #     df_data[f'user_tag_{col}_rate'] = df_data[f'user_tag_{col}_sum']/df_data['user_tag_cnt']\n",
    "    #     df_data[f'userid_{col}_mes'] = df_data[f'userid_{col}_mean']/df_data[f'userid_{col}_std']\n",
    "    #     df_data[f'videoid_{col}_mes'] = df_data[f'videoid_{col}_mean']/df_data[f'videoid_{col}_std']\n",
    "    #     df_data[f'tag_{col}_mes'] = df_data[f'tag_{col}_mean']/df_data[f'tag_{col}_std']\n",
    "    # df_data.head()\n",
    "    df_data = reduce_mem_usage(df_data)\n",
    "    print(datatype,df_data.shape)\n",
    "    df_data.to_pickle(f'../temp_data/df_{datatype}_v6.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
